{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be7b333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found existing raw data file: acs_pums_2023.parquet\n",
      "Skipping download step...\n",
      "Loaded 3,405,809 records from existing file\n",
      "Loaded 3,405,809 records from existing file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>OCCP</th>\n",
       "      <th>INDP</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>RAC3P</th>\n",
       "      <th>WKHP</th>\n",
       "      <th>ESR</th>\n",
       "      <th>STATE</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>12200</td>\n",
       "      <td>001</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>001</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>108000</td>\n",
       "      <td>029</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>08</td>\n",
       "      <td>08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>002</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>4220</td>\n",
       "      <td>7580</td>\n",
       "      <td>5200</td>\n",
       "      <td>002</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  AGEP SEX SCHL  OCCP  INDP   PINCP RAC3P WKHP ESR STATE state\n",
       "0   94   2   16     N     N   12200   001    0   6    34    34\n",
       "1   18   1   19     N     N       0   001    0   6    34    34\n",
       "2   75   1   21     N     N  108000   029    0   6    08    08\n",
       "3   44   1   18     N     N       0   002    0   6    12    12\n",
       "4   31   1   18  4220  7580    5200   002   20   6    39    39"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def download_census_data(api_key, output_file=\"acs_pums_2023.parquet\"):\n",
    "    \"\"\"\n",
    "    Download census data from the API and save to parquet file.\n",
    "    \n",
    "    Args:\n",
    "        api_key: Census API key\n",
    "        output_file: Path to save the parquet file\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The downloaded census data\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        \"https://api.census.gov/data/2023/acs/acs1/pums?\"\n",
    "        \"get=AGEP,SEX,SCHL,OCCP,INDP,PINCP,RAC3P,WKHP,ESR,STATE\"\n",
    "        f\"&for=state:*&key={api_key}\"\n",
    "    )\n",
    "    \n",
    "    print(\"Fetching census data from API...\")\n",
    "    response = requests.get(url)\n",
    "    print(f\"Status: {response.status_code}\")\n",
    "    print(f\"Content-Type: {response.headers.get('Content-Type')}\")\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.text[:500]}\")\n",
    "        raise SystemExit(\"Failed to download census data\")\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    # Convert JSON → DataFrame\n",
    "    columns = data[0]\n",
    "    rows = data[1:]\n",
    "    df = pd.DataFrame(rows, columns=columns)\n",
    "    \n",
    "    # Save to parquet\n",
    "    df.to_parquet(output_file, index=False)\n",
    "    print(f\"✓ Saved {len(df):,} records to: {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Check if raw data already exists\n",
    "RAW_DATA_FILE = \"acs_pums_2023.parquet\"\n",
    "\n",
    "if os.path.exists(RAW_DATA_FILE):\n",
    "    print(f\"✓ Found existing raw data file: {RAW_DATA_FILE}\")\n",
    "    print(\"Skipping download step...\")\n",
    "    df = pd.read_parquet(RAW_DATA_FILE)\n",
    "    print(f\"Loaded {len(df):,} records from existing file\")\n",
    "else:\n",
    "    print(f\"Raw data file not found. Downloading...\")\n",
    "    API_KEY = \"71cbe35ff6e0c0df92b72d8a233c40a85de5b0b9\"\n",
    "    df = download_census_data(API_KEY, RAW_DATA_FILE)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5587d2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found existing labeled data file: acs_pums_2023_labeled.parquet\n",
      "Skipping labeling step...\n",
      "Loaded 3,405,809 labeled records from existing file\n",
      "\n",
      "Final labeled DataFrame preview:\n",
      "Loaded 3,405,809 labeled records from existing file\n",
      "\n",
      "Final labeled DataFrame preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Annual Income</th>\n",
       "      <th>Weekly Work Hours</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Educational attainment</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Race</th>\n",
       "      <th>Employment status recode</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>12200</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regular high school diploma</td>\n",
       "      <td>N/A (less than 16 years old/NILF who last work...</td>\n",
       "      <td>N/A (less than 16 years old/NILF who last work...</td>\n",
       "      <td>White alone</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>New Jersey/NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>1 or more years of college credit, no degree</td>\n",
       "      <td>N/A (less than 16 years old/NILF who last work...</td>\n",
       "      <td>N/A (less than 16 years old/NILF who last work...</td>\n",
       "      <td>White alone</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>New Jersey/NJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>108000</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>N/A (less than 16 years old/NILF who last work...</td>\n",
       "      <td>N/A (less than 16 years old/NILF who last work...</td>\n",
       "      <td>White; Some Other Race</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>Colorado/CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Some college, but less than 1 year</td>\n",
       "      <td>N/A (less than 16 years old/NILF who last work...</td>\n",
       "      <td>N/A (less than 16 years old/NILF who last work...</td>\n",
       "      <td>Black or African American alone</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>Florida/FL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>5200</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>Some college, but less than 1 year</td>\n",
       "      <td>CLN-Janitors And Building Cleaners</td>\n",
       "      <td>PRF-Employment Services</td>\n",
       "      <td>Black or African American alone</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>Ohio/OH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Age Annual Income Weekly Work Hours     Sex  \\\n",
       "0  94         12200                 0  Female   \n",
       "1  18             0                 0    Male   \n",
       "2  75        108000                 0    Male   \n",
       "3  44             0                 0    Male   \n",
       "4  31          5200                20    Male   \n",
       "\n",
       "                         Educational attainment  \\\n",
       "0                   Regular high school diploma   \n",
       "1  1 or more years of college credit, no degree   \n",
       "2                             Bachelor's degree   \n",
       "3            Some college, but less than 1 year   \n",
       "4            Some college, but less than 1 year   \n",
       "\n",
       "                                          Occupation  \\\n",
       "0  N/A (less than 16 years old/NILF who last work...   \n",
       "1  N/A (less than 16 years old/NILF who last work...   \n",
       "2  N/A (less than 16 years old/NILF who last work...   \n",
       "3  N/A (less than 16 years old/NILF who last work...   \n",
       "4                 CLN-Janitors And Building Cleaners   \n",
       "\n",
       "                                            Industry  \\\n",
       "0  N/A (less than 16 years old/NILF who last work...   \n",
       "1  N/A (less than 16 years old/NILF who last work...   \n",
       "2  N/A (less than 16 years old/NILF who last work...   \n",
       "3  N/A (less than 16 years old/NILF who last work...   \n",
       "4                            PRF-Employment Services   \n",
       "\n",
       "                              Race Employment status recode          State  \n",
       "0                      White alone       Not in Labor Force  New Jersey/NJ  \n",
       "1                      White alone       Not in Labor Force  New Jersey/NJ  \n",
       "2           White; Some Other Race       Not in Labor Force    Colorado/CO  \n",
       "3  Black or African American alone       Not in Labor Force     Florida/FL  \n",
       "4  Black or African American alone       Not in Labor Force        Ohio/OH  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def label_census_data(input_file, code_ref_file=\"code_reference.json\", output_file=\"acs_pums_2023_labeled.parquet\"):\n",
    "    \"\"\"\n",
    "    Label census data using code reference mappings.\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to raw parquet file\n",
    "        code_ref_file: Path to code reference JSON file\n",
    "        output_file: Path to save labeled parquet file\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The labeled census data\n",
    "    \"\"\"\n",
    "    print(\"--- Starting JSON code mapping for the dataframe ---\")\n",
    "    \n",
    "    # Load code reference\n",
    "    with open(code_ref_file, 'r', encoding='utf-8') as f:\n",
    "        code_ref = pd.read_json(f)\n",
    "    \n",
    "    # Helper function to build value map from code reference\n",
    "    def build_value_map(col_spec):\n",
    "        \"\"\"\n",
    "        Extract the mapping dictionary from the code reference structure.\n",
    "        col_spec: the column specification from code_ref (e.g., code_ref['SEX'])\n",
    "        Returns: dict mapping code values to labels\n",
    "        \"\"\"\n",
    "        if 'values' in col_spec and 'item' in col_spec['values']:\n",
    "            return col_spec['values']['item']\n",
    "        return {}\n",
    "    \n",
    "    # Helper function to map a series using the value map\n",
    "    def map_series_with_codes(series, value_map):\n",
    "        \"\"\"\n",
    "        Map a pandas Series using a value map dictionary.\n",
    "        Converts numeric codes to string labels.\n",
    "        series: pandas Series to map\n",
    "        value_map: dict mapping codes to labels\n",
    "        Returns: mapped pandas Series\n",
    "        \"\"\"\n",
    "        # Convert series to string for mapping (handles both int and string keys)\n",
    "        return series.astype(str).map(value_map).fillna(series.astype(str))\n",
    "    \n",
    "    # Load the parquet file\n",
    "    df = pd.read_parquet(input_file)\n",
    "    \n",
    "    # Define the columns we want to decode from code_reference.json\n",
    "    cols_to_decode = [\n",
    "        \"SEX\", \"SCHL\", \"OCCP\", \"INDP\",\n",
    "        \"RAC3P\", \"ESR\", \"STATE\"\n",
    "    ]\n",
    "    \n",
    "    # Define simple column renames (no value mapping needed)\n",
    "    cols_to_rename = {\n",
    "        \"AGEP\": \"Age\",\n",
    "        \"PINCP\": \"Annual Income\",\n",
    "        \"WKHP\": \"Weekly Work Hours\"\n",
    "    }\n",
    "    \n",
    "    # Keep track of columns to remove\n",
    "    cols_to_remove = []\n",
    "    \n",
    "    # Loop through and apply mappings from code_reference.json\n",
    "    for col_name in cols_to_decode:\n",
    "        # Check if column exists in 'df'\n",
    "        if col_name in df.columns:\n",
    "            # Check if column exists in 'code_ref' JSON\n",
    "            if col_name in code_ref:\n",
    "                try:\n",
    "                    # Get the value mapping table (e.g., {\"1\": \"Male\", \"2\": \"Female\"})\n",
    "                    vmap = build_value_map(code_ref[col_name])\n",
    "                    \n",
    "                    # Get the friendly name for the new column (e.g., \"Sex\")\n",
    "                    new_col_label = code_ref[col_name].get('label', f\"{col_name}_LABEL\")\n",
    "                    \n",
    "                    # Apply the mapping function to create the new column\n",
    "                    df[new_col_label] = map_series_with_codes(df[col_name], vmap)\n",
    "                    \n",
    "                    # Mark the original column for removal\n",
    "                    cols_to_remove.append(col_name)\n",
    "                    \n",
    "                    print(f\"Success: Mapped '{col_name}' to new column '{new_col_label}'\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: Failed to map '{col_name}': {e}\")\n",
    "            else:\n",
    "                print(f\"Skipped: Key '{col_name}' not found in code_ref\")\n",
    "        else:\n",
    "            print(f\"Skipped: Column '{col_name}' not found in DataFrame\")\n",
    "    \n",
    "    # Rename simple columns (just copy values with new name)\n",
    "    for old_name, new_name in cols_to_rename.items():\n",
    "        if old_name in df.columns:\n",
    "            df[new_name] = df[old_name]\n",
    "            cols_to_remove.append(old_name)\n",
    "            print(f\"Success: Renamed '{old_name}' to '{new_name}'\")\n",
    "        else:\n",
    "            print(f\"Skipped: Column '{old_name}' not found in DataFrame\")\n",
    "    \n",
    "    # Remove duplicate \"state\" column if it exists (lowercase version)\n",
    "    if 'state' in df.columns:\n",
    "        cols_to_remove.append('state')\n",
    "        print(f\"Success: Marked duplicate 'state' column for removal\")\n",
    "    \n",
    "    # Remove the original coded columns\n",
    "    if cols_to_remove:\n",
    "        df = df.drop(columns=cols_to_remove)\n",
    "        print(f\"\\n--- Removed {len(cols_to_remove)} original coded columns: {cols_to_remove} ---\")\n",
    "    \n",
    "    # Reorder columns: Age, Annual Income, Weekly Work Hours first, then others\n",
    "    priority_cols = [\"Age\", \"Annual Income\", \"Weekly Work Hours\"]\n",
    "    existing_priority = [col for col in priority_cols if col in df.columns]\n",
    "    other_cols = [col for col in df.columns if col not in priority_cols]\n",
    "    new_col_order = existing_priority + other_cols\n",
    "    df = df[new_col_order]\n",
    "    \n",
    "    # Save labeled data\n",
    "    df.to_parquet(output_file, index=False)\n",
    "    print(f\"\\n--- Mapping complete. ---\")\n",
    "    print(f\"✓ Saved {len(df):,} labeled records to: {output_file}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Check if labeled data already exists\n",
    "LABELED_DATA_FILE = \"acs_pums_2023_labeled.parquet\"\n",
    "\n",
    "if os.path.exists(LABELED_DATA_FILE):\n",
    "    print(f\"✓ Found existing labeled data file: {LABELED_DATA_FILE}\")\n",
    "    print(\"Skipping labeling step...\")\n",
    "    df = pd.read_parquet(LABELED_DATA_FILE)\n",
    "    print(f\"Loaded {len(df):,} labeled records from existing file\")\n",
    "else:\n",
    "    print(f\"Labeled data file not found. Starting labeling process...\")\n",
    "    df = label_census_data(RAW_DATA_FILE, output_file=LABELED_DATA_FILE)\n",
    "\n",
    "print(f\"\\nFinal labeled DataFrame preview:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc273178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Synthetic Data Generation ---\n",
      "Initial data shape: (3405809, 10)\n",
      "Initial data shape: (3405809, 10)\n",
      "Cleaned data shape: (2818857, 10)\n",
      "Calculating stratum weights...\n",
      "Sampling 1,000,000 records across 14 strata...\n",
      "Cleaned data shape: (2818857, 10)\n",
      "Calculating stratum weights...\n",
      "Sampling 1,000,000 records across 14 strata...\n",
      "Generated 1,000,001 raw synthetic records.\n",
      "\n",
      "--- Running Reasonableness Check ---\n",
      "Found 13,442 illogical records (1.34%)\n",
      "Filtered data shape: (986559, 11)\n",
      "\n",
      "--- Applying Privacy Noise ---\n",
      "  Shuffled: state\n",
      "  Shuffled: race\n",
      "  Shuffled: educational_attainment\n",
      "Generated 1,000,001 raw synthetic records.\n",
      "\n",
      "--- Running Reasonableness Check ---\n",
      "Found 13,442 illogical records (1.34%)\n",
      "Filtered data shape: (986559, 11)\n",
      "\n",
      "--- Applying Privacy Noise ---\n",
      "  Shuffled: state\n",
      "  Shuffled: race\n",
      "  Shuffled: educational_attainment\n",
      "  Shuffled: occupation\n",
      "\n",
      "Final synthetic demographics shape: (986559, 6)\n",
      "Columns: ['age', 'gender', 'state', 'race', 'educational_attainment', 'occupation']\n",
      "\n",
      "--- Running Validation Checks (Jensen-Shannon Divergence) ---\n",
      "  JS(age                      ) = 0.0003\n",
      "  JS(gender                   ) = 0.0000\n",
      "  JS(state                    ) = 0.0000\n",
      "  JS(race                     ) = 0.0000\n",
      "  JS(educational_attainment   ) = 0.0000\n",
      "  JS(occupation               ) = 0.0001\n",
      "\n",
      "--- Correlation Preservation Check ---\n",
      "Real Data Correlation:\n",
      "  Shuffled: occupation\n",
      "\n",
      "Final synthetic demographics shape: (986559, 6)\n",
      "Columns: ['age', 'gender', 'state', 'race', 'educational_attainment', 'occupation']\n",
      "\n",
      "--- Running Validation Checks (Jensen-Shannon Divergence) ---\n",
      "  JS(age                      ) = 0.0003\n",
      "  JS(gender                   ) = 0.0000\n",
      "  JS(state                    ) = 0.0000\n",
      "  JS(race                     ) = 0.0000\n",
      "  JS(educational_attainment   ) = 0.0000\n",
      "  JS(occupation               ) = 0.0001\n",
      "\n",
      "--- Correlation Preservation Check ---\n",
      "Real Data Correlation:\n",
      "         age  pincp   wkhp\n",
      "age    1.000  0.087 -0.335\n",
      "pincp  0.087  1.000  0.366\n",
      "wkhp  -0.335  0.366  1.000\n",
      "\n",
      "Synthetic Data Correlation:\n",
      "         age  pincp   wkhp\n",
      "age    1.000  0.082 -0.337\n",
      "pincp  0.082  1.000  0.369\n",
      "wkhp  -0.337  0.369  1.000\n",
      "\n",
      "--- Saving Synthetic Demographics ---\n",
      "✓ Saved 986,559 records to: synthetic_demographics_1m.parquet\n",
      "✓ Saved preview (1000 records) to: synthetic_demographics_1m.csv\n",
      "\n",
      "--- Synthetic Data Generation Complete ---\n",
      "Final dataset preview:\n",
      "         age  pincp   wkhp\n",
      "age    1.000  0.087 -0.335\n",
      "pincp  0.087  1.000  0.366\n",
      "wkhp  -0.335  0.366  1.000\n",
      "\n",
      "Synthetic Data Correlation:\n",
      "         age  pincp   wkhp\n",
      "age    1.000  0.082 -0.337\n",
      "pincp  0.082  1.000  0.369\n",
      "wkhp  -0.337  0.369  1.000\n",
      "\n",
      "--- Saving Synthetic Demographics ---\n",
      "✓ Saved 986,559 records to: synthetic_demographics_1m.parquet\n",
      "✓ Saved preview (1000 records) to: synthetic_demographics_1m.csv\n",
      "\n",
      "--- Synthetic Data Generation Complete ---\n",
      "Final dataset preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>race</th>\n",
       "      <th>educational_attainment</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>Female</td>\n",
       "      <td>Nebraska/NE</td>\n",
       "      <td>White alone</td>\n",
       "      <td>Bachelor's degree</td>\n",
       "      <td>MGR-Financial Managers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>Texas/TX</td>\n",
       "      <td>White alone</td>\n",
       "      <td>Associate's degree</td>\n",
       "      <td>ENT-Producers And Directors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>Massachusetts/MA</td>\n",
       "      <td>White alone</td>\n",
       "      <td>Doctorate degree</td>\n",
       "      <td>EDU-Postsecondary Teachers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>Female</td>\n",
       "      <td>Texas/TX</td>\n",
       "      <td>White alone</td>\n",
       "      <td>Master's degree</td>\n",
       "      <td>EDU-Special Education Teachers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>Female</td>\n",
       "      <td>California/CA</td>\n",
       "      <td>Some Other Race alone</td>\n",
       "      <td>12th grade - no diploma</td>\n",
       "      <td>N/A (less than 16 years old/NILF who last work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender             state                   race  \\\n",
       "0   17  Female       Nebraska/NE            White alone   \n",
       "1   20  Female          Texas/TX            White alone   \n",
       "2   20  Female  Massachusetts/MA            White alone   \n",
       "3   18  Female          Texas/TX            White alone   \n",
       "4   18  Female     California/CA  Some Other Race alone   \n",
       "\n",
       "    educational_attainment                                         occupation  \n",
       "0        Bachelor's degree                             MGR-Financial Managers  \n",
       "1       Associate's degree                        ENT-Producers And Directors  \n",
       "2         Doctorate degree                         EDU-Postsecondary Teachers  \n",
       "3          Master's degree                     EDU-Special Education Teachers  \n",
       "4  12th grade - no diploma  N/A (less than 16 years old/NILF who last work...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "import os\n",
    "\n",
    "print(\"--- Starting Synthetic Data Generation ---\")\n",
    "\n",
    "# --- 1. Setup: Load and Rename Data ---\n",
    "def get_label(key, default):\n",
    "    \"\"\"Get label from code_ref dictionary, with fallback to default.\"\"\"\n",
    "    try:\n",
    "        return code_ref[key].get('label', default)\n",
    "    except KeyError:\n",
    "        return default\n",
    "\n",
    "# Map labeled columns to simplified names for processing\n",
    "rename_map = {\n",
    "    'Age': 'age',\n",
    "    'Sex': 'gender',\n",
    "    'State': 'state',\n",
    "    'Race': 'race',\n",
    "    'Annual Income': 'pincp',\n",
    "    'Weekly Work Hours': 'wkhp',\n",
    "    'Educational attainment': 'educational_attainment',\n",
    "    'Occupation': 'occupation',\n",
    "    'Employment status recode': 'employment_status',\n",
    "    'Industry': 'industry'\n",
    "}\n",
    "\n",
    "# Select and rename columns\n",
    "cols_to_keep = [col for col in rename_map.keys() if col in df.columns]\n",
    "d = df[cols_to_keep].rename(columns=rename_map)\n",
    "print(f\"Initial data shape: {d.shape}\")\n",
    "\n",
    "# --- 2. Data Cleaning and Type Conversion ---\n",
    "# Convert numeric columns\n",
    "for col in ['age', 'pincp', 'wkhp']:\n",
    "    if col in d.columns:\n",
    "        d[col] = pd.to_numeric(d[col], errors='coerce')\n",
    "\n",
    "# Drop rows with missing critical data\n",
    "d = d.dropna(subset=['age', 'gender', 'state'])\n",
    "\n",
    "# Filter age range\n",
    "d = d[(d.age >= 16) & (d.age <= 90)]\n",
    "d['age'] = d['age'].astype(int)\n",
    "\n",
    "# Convert categorical columns\n",
    "cat_cols = ['gender', 'state', 'race', 'educational_attainment',\n",
    "            'occupation', 'employment_status', 'industry']\n",
    "for c in cat_cols:\n",
    "    if c in d.columns:\n",
    "        d[c] = d[c].fillna(\"Not Applicable\").astype(\"category\")\n",
    "\n",
    "print(f\"Cleaned data shape: {d.shape}\")\n",
    "\n",
    "# --- 3. Stratified Sampling ---\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# Create age bins for stratification\n",
    "age_bins = [16, 20, 30, 40, 50, 60, 70, 91]\n",
    "d[\"age_bin\"] = pd.cut(d[\"age\"], bins=age_bins, right=False)\n",
    "\n",
    "# Stratify by gender and age\n",
    "strata = [\"gender\", \"age_bin\"]\n",
    "target_n = 1_000_000  # Generate 1 million records\n",
    "\n",
    "print(\"Calculating stratum weights...\")\n",
    "strata_weights = d.groupby(strata, observed=True).size()\n",
    "strata_weights = strata_weights / strata_weights.sum()\n",
    "\n",
    "print(f\"Sampling {target_n:,} records across {len(strata_weights)} strata...\")\n",
    "samples = []\n",
    "\n",
    "for idx, proportion in strata_weights.items():\n",
    "    stratum_data = d[(d[\"gender\"] == idx[0]) & (d[\"age_bin\"] == idx[1])]\n",
    "    \n",
    "    if len(stratum_data) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calculate number of samples for this stratum\n",
    "    n_samples = int(round(proportion * target_n))\n",
    "    \n",
    "    if n_samples == 0:\n",
    "        continue\n",
    "    \n",
    "    # Sample with replacement\n",
    "    sampled = stratum_data.sample(n=n_samples, replace=True, random_state=42)\n",
    "    samples.append(sampled)\n",
    "\n",
    "syn = pd.concat(samples, ignore_index=True)\n",
    "print(f\"Generated {len(syn):,} raw synthetic records.\")\n",
    "\n",
    "# --- 4. Reasonableness Check ---\n",
    "print(\"\\n--- Running Reasonableness Check ---\")\n",
    "\n",
    "# Define illogical conditions\n",
    "invalid_mask = (\n",
    "    # Unemployed or not in labor force shouldn't have work hours\n",
    "    ((syn['employment_status'] == 'Unemployed') & (syn['wkhp'] > 0)) |\n",
    "    ((syn['employment_status'] == 'Not in labor force') & (syn['wkhp'] > 0)) |\n",
    "    # Students shouldn't have very high income or excessive work hours\n",
    "    ((syn['occupation'].str.contains('Student', na=False)) & (syn['pincp'] > 100000)) |\n",
    "    ((syn['occupation'].str.contains('Student', na=False)) & (syn['wkhp'] > 40))\n",
    ")\n",
    "\n",
    "invalid_count = invalid_mask.sum()\n",
    "print(f\"Found {invalid_count:,} illogical records ({100*invalid_count/len(syn):.2f}%)\")\n",
    "\n",
    "# Filter out invalid records\n",
    "syn_filtered = syn[~invalid_mask].copy()\n",
    "print(f\"Filtered data shape: {syn_filtered.shape}\")\n",
    "\n",
    "# --- 5. Apply Privacy Noise ---\n",
    "print(\"\\n--- Applying Privacy Noise ---\")\n",
    "\n",
    "# Add jitter to age to prevent exact copy risk\n",
    "syn_filtered[\"age\"] = (\n",
    "    syn_filtered[\"age\"].astype(float) + \n",
    "    rng.integers(-2, 3, size=len(syn_filtered))\n",
    ")\n",
    "syn_filtered[\"age\"] = syn_filtered[\"age\"].clip(16, 90).round().astype(int)\n",
    "\n",
    "# Shuffle categorical columns to add privacy noise\n",
    "cols_to_shuffle = ['state', 'race', 'educational_attainment', 'occupation']\n",
    "for col in cols_to_shuffle:\n",
    "    if col in syn_filtered.columns:\n",
    "        syn_filtered[col] = syn_filtered[col].sample(frac=1, random_state=42).values\n",
    "        print(f\"  Shuffled: {col}\")\n",
    "\n",
    "# --- 6. Select Final Columns for Demographics ---\n",
    "cols_for_output = [\n",
    "    \"age\", \"gender\", \"state\", \"race\",\n",
    "    \"educational_attainment\", \"occupation\"\n",
    "]\n",
    "\n",
    "# Ensure we only select columns that exist\n",
    "final_cols = [col for col in cols_for_output if col in syn_filtered.columns]\n",
    "syn_demo = syn_filtered[final_cols].copy()\n",
    "\n",
    "print(f\"\\nFinal synthetic demographics shape: {syn_demo.shape}\")\n",
    "print(f\"Columns: {list(syn_demo.columns)}\")\n",
    "\n",
    "# --- 7. Validation Checks ---\n",
    "print(\"\\n--- Running Validation Checks (Jensen-Shannon Divergence) ---\")\n",
    "\n",
    "def jensen_shannon_divergence(p, q):\n",
    "    \"\"\"Calculate Jensen-Shannon divergence between two distributions.\"\"\"\n",
    "    p = p / p.sum()\n",
    "    q = q / q.sum()\n",
    "    m = 0.5 * (p + q)\n",
    "    \n",
    "    # Avoid log(0)\n",
    "    p = np.where(p == 0, 1e-10, p)\n",
    "    q = np.where(q == 0, 1e-10, q)\n",
    "    m = np.where(m == 0, 1e-10, m)\n",
    "    \n",
    "    return 0.5 * ss.entropy(p, m) + 0.5 * ss.entropy(q, m)\n",
    "\n",
    "# Validate distributions for each column\n",
    "validation_cols = ['age', 'gender', 'state', 'race', \n",
    "                   'educational_attainment', 'occupation']\n",
    "\n",
    "for col in validation_cols:\n",
    "    if col in d.columns and col in syn_demo.columns:\n",
    "        real_dist = d[col].value_counts().sort_index()\n",
    "        syn_dist = syn_demo[col].value_counts().sort_index()\n",
    "        syn_dist = syn_dist.reindex(real_dist.index, fill_value=0)\n",
    "        \n",
    "        js_score = jensen_shannon_divergence(real_dist.values, syn_dist.values)\n",
    "        print(f\"  JS({col:25s}) = {js_score:.4f}\")\n",
    "\n",
    "# Correlation preservation check\n",
    "print(\"\\n--- Correlation Preservation Check ---\")\n",
    "def calculate_correlation(data, cols):\n",
    "    \"\"\"Calculate correlation matrix, handling categorical variables.\"\"\"\n",
    "    df_numeric = data[cols].copy()\n",
    "    for c in cols:\n",
    "        if str(df_numeric[c].dtype) == \"category\":\n",
    "            df_numeric[c] = df_numeric[c].cat.codes\n",
    "    return df_numeric.corr(numeric_only=True)\n",
    "\n",
    "cols_for_corr = [\"age\", \"pincp\", \"wkhp\"]\n",
    "present_cols = [c for c in cols_for_corr if c in d.columns]\n",
    "\n",
    "if len(present_cols) >= 2:\n",
    "    print(\"Real Data Correlation:\")\n",
    "    c_real = calculate_correlation(d, present_cols)\n",
    "    print(c_real.round(3))\n",
    "    \n",
    "    print(\"\\nSynthetic Data Correlation:\")\n",
    "    c_syn = calculate_correlation(syn_filtered, present_cols)\n",
    "    print(c_syn.round(3))\n",
    "\n",
    "# --- 8. Save Synthetic Demographics ---\n",
    "print(\"\\n--- Saving Synthetic Demographics ---\")\n",
    "\n",
    "# Save to current directory\n",
    "save_path = \"synthetic_demographics_1m.parquet\"\n",
    "syn_demo.to_parquet(save_path, index=False)\n",
    "print(f\"✓ Saved {len(syn_demo):,} records to: {save_path}\")\n",
    "\n",
    "# Also save to CSV for easy viewing\n",
    "csv_path = \"synthetic_demographics_1m.csv\"\n",
    "syn_demo.head(1000).to_csv(csv_path, index=False)\n",
    "print(f\"✓ Saved preview (1000 records) to: {csv_path}\")\n",
    "\n",
    "print(\"\\n--- Synthetic Data Generation Complete ---\")\n",
    "print(f\"Final dataset preview:\")\n",
    "syn_demo.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
